{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_INIT_FILE = 'model_desc.txt'\n",
    "IMAGE_DATASET_DIR = './TRAIN_IMAGES/'\n",
    "CSV_FILE = 'training-a_revised.csv'\n",
    "MINI_BATCH_SIZE = 64\n",
    "IMAGE_DIM = 180 # Height and width of the image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SOFTMAX LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_Layer:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'Softmax'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Layer\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z = np.exp(X)\n",
    "        return Z / np.einsum('ij->j', Z)\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        return np.copy(dZ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ReLU ACTIVATION </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_Activation:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'ReLU'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Activation\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        Z = np.copy(X)\n",
    "        Z[Z < 0] = 0\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.copy(self.X)\n",
    "\n",
    "        dX[dX < 0] = 0\n",
    "        dX[dX > 0] = 1\n",
    "        return dX * dZ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FULLY CONNECTED LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fully_Connected_Layer:\n",
    "    def __init__(self, output_dim):\n",
    "        self.output_dim = output_dim\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Fully Connected Layer(output_dim={self.output_dim})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        if self.W is None:\n",
    "            self.W = np.random.randn(X.shape[1], self.output_dim) * math.sqrt(2 / X.shape[0])\n",
    "        \n",
    "        if self.b is None:\n",
    "            self.b = np.zeros((1, self.output_dim))\n",
    "\n",
    "        Z = np.einsum('ij,jk->ik', X, self.W) + self.b\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dW = np.einsum('ij,ik->jk', self.X, dZ) / self.X.shape[1] # check here\n",
    "        db = np.einsum('ij->j', dZ) / self.X.shape[0] # check here\n",
    "        dX = np.einsum('ij,jk->ik', dZ, self.W.T)\n",
    "\n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FLATENNING LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatenning_Layer:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'Flatten'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Layer\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input_shape = X.shape\n",
    "        return X.reshape((X.shape[0], -1)) # check here\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.copy(dZ)\n",
    "        return dX.reshape(self.input_shape) # check here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MAX POOLING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pooling:\n",
    "    def __init__(self, filter_dim, stride):\n",
    "        self.layer_type = 'Max Pooling'\n",
    "        self.filter_dim = filter_dim\n",
    "        self.stride = stride\n",
    "        self.X = None\n",
    "        self.Z_Max_idx = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} (filter_dim={self.filter_dim}, stride={self.stride})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        output_dim = (X.shape[1] - self.filter_dim) // self.stride + 1\n",
    "        Z = np.zeros((X.shape[0], output_dim, output_dim, X.shape[3]))\n",
    "        self.Z_Max_idx = np.zeros((Z.shape), dtype=np.int32)\n",
    "\n",
    "        for k in range(X.shape[0]):\n",
    "            for l in range(X.shape[3]):\n",
    "                for i in range(output_dim):\n",
    "                    for j in range(output_dim):\n",
    "                        p = X[k, i * self.stride: i * self.stride + self.filter_dim,\n",
    "                                   j * self.stride: j * self.stride + self.filter_dim, l]\n",
    "                        Z[k, i, j, l] = np.max(p)\n",
    "                        self.Z_Max_idx[k, i, j, l] = np.argmax(p)\n",
    "\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.zeros(self.X.shape)\n",
    "        # print(f\"shape of dZ: {dZ.shape}\")\n",
    "        # print(dZ)\n",
    "        for k in range(self.X.shape[0]):\n",
    "            for l in range(self.X.shape[3]):\n",
    "                for i in range(self.X.shape[1]):\n",
    "                    for j in range(self.X.shape[2]):\n",
    "                        p_idx = (i // self.stride, j // self.stride, l)\n",
    "                        dX[k, i, j, l] = dZ[k, i//self.stride, j//self.stride, l] * (self.Z_Max_idx[k, i//self.stride, j//self.stride, l] == (i%self.stride)*self.filter_dim + j%self.stride)\n",
    "        # print(f\"shape of dX: {dX.shape}\")\n",
    "        # print(dX)\n",
    "        return dX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CONVOLUTION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, num_output_channels, filter_dim, stride=1, padding=0):\n",
    "        self.layer_type = 'Convolution'\n",
    "        self.num_output_channels = num_output_channels\n",
    "        self.filter_dim = filter_dim\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} (num_output_channels={self.num_output_channels}, filter_dim={self.filter_dim}, stride={self.stride}, padding={self.padding})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        self.output_dim = (X.shape[1] - self.filter_dim + 2 * self.padding) // self.stride + 1\n",
    "\n",
    "        # padding\n",
    "        X = np.pad(X, ((0, 0), (self.padding, self.padding), (self.padding, self.padding), (0, 0)), 'constant')\n",
    "\n",
    "        Z = np.zeros((X.shape[0], self.output_dim, self.output_dim, self.num_output_channels))\n",
    "\n",
    "        if self.W is None:\n",
    "            self.W = np.random.randn(self.num_output_channels, self.filter_dim, self.filter_dim, X.shape[3]) * math.sqrt(2 / X.shape[0])\n",
    "        if self.b is None:\n",
    "            self.b = np.zeros((self.num_output_channels))\n",
    "        \n",
    "\n",
    "        # print(self.W.shape)\n",
    "        # print(self.b.shape)\n",
    "        # print(X.shape)\n",
    "        # print(Z.shape)\n",
    "\n",
    "        for channel in range(self.num_output_channels):\n",
    "            for i in range(self.output_dim):\n",
    "                for j in range(self.output_dim):\n",
    "                    Z[:, i, j, channel] = np.sum(X[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :] * self.W[channel, :, :, :], axis=(1, 2, 3)) + self.b[channel]\n",
    "\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dW = np.zeros((self.num_output_channels, self.filter_dim, self.filter_dim, self.X.shape[3]))\n",
    "        db = np.zeros((self.num_output_channels))\n",
    "        dX = np.zeros(self.X.shape)\n",
    "\n",
    "        for channel in range(self.num_output_channels):\n",
    "            for i in range(self.output_dim):\n",
    "                for j in range(self.output_dim):\n",
    "                    dW[channel, :, :, :] += np.sum(self.X[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :] * dZ[:, i, j, channel].reshape((dZ.shape[0], 1, 1, 1)), axis=0)/dZ.shape[0]\n",
    "                    dX[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :] += self.W[channel, :, :, :] * dZ[:, i, j, channel].reshape((dZ.shape[0], 1, 1, 1))/dZ.shape[0]\n",
    "                    db[channel] += np.sum(dZ[:, i, j, channel])\n",
    "        \n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, filePath):\n",
    "        self.layers = []\n",
    "        self.filePath = filePath\n",
    "        self.build_model()\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'MODEL DETAILS:\\n\\n'\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            string += f\"Layer {i+1}: {layer}\\n\"\n",
    "        return string\n",
    "    \n",
    "    def build_model(self):\n",
    "        #check if file exists\n",
    "        if not os.path.exists(self.filePath):\n",
    "            print('File does not exist')\n",
    "            return\n",
    "        with open(self.filePath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line == '':\n",
    "                    continue\n",
    "\n",
    "                line_split = line.split(' ')\n",
    "                layer_name = str(line_split[0]).upper()\n",
    "                \n",
    "                if layer_name == 'FC':\n",
    "                    output_dim = int(line_split[1])\n",
    "                    self.layers.append(Fully_Connected_Layer(output_dim))\n",
    "\n",
    "                elif layer_name == 'CONV':\n",
    "                    num_output_channels = int(line_split[1])\n",
    "                    filter_dim = int(line_split[2])\n",
    "                    stride = int(line_split[3])\n",
    "                    padding = int(line_split[4])\n",
    "                    self.layers.append(Convolution(num_output_channels, filter_dim, stride, padding))\n",
    "\n",
    "                elif layer_name == 'MAXPOOL':\n",
    "                    filter_dim = int(line_split[1])\n",
    "                    stride = int(line_split[2])\n",
    "                    self.layers.append(Max_Pooling(filter_dim, stride))\n",
    "\n",
    "                elif layer_name == 'FLATTEN':\n",
    "                    self.layers.append(Flatenning_Layer())\n",
    "\n",
    "                elif layer_name == 'RELU':\n",
    "                    self.layers.append(ReLU_Activation())\n",
    "\n",
    "                elif layer_name == 'SOFTMAX':\n",
    "                    self.layers.append(Softmax_Layer())\n",
    "                \n",
    "                else:\n",
    "                    print('Invalid layer name')\n",
    "                    return\n",
    "        \n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            # print(\"forward : \", layer)\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        for layer in reversed(self.layers):\n",
    "            # print(\"Backward : \",layer)\n",
    "            dZ = layer.backward(dZ, learning_rate)\n",
    "        return dZ\n",
    "    \n",
    "    def train(self, X, Y, learning_rate=0.0001, epochs=10):\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            Z = self.forward(X)\n",
    "            dZ = Z - Y\n",
    "            self.backward(dZ, learning_rate)\n",
    "            # print(f\"Epoch {epoch+1} completed\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        Z = self.forward(X)\n",
    "        return np.argmax(Z, axis=1)\n",
    "    \n",
    "    def evaluate(self, X, Y):\n",
    "        Y_pred = self.predict(X)\n",
    "        Y_true = np.argmax(Y, axis=1)\n",
    "        return np.sum(Y_pred == Y_true) / len(Y_true) * 100\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resizing the image\n",
    "    img = cv2.resize(img,(IMAGE_DIM, IMAGE_DIM))\n",
    "    # reshaping the image\n",
    "    img = img.reshape(IMAGE_DIM, IMAGE_DIM, 1) # 1 for grayscale\n",
    "    # Displaying the image\n",
    "    # plt.imshow(img, cmap='gray')\n",
    "    # plt.show()\n",
    "    # print(img.shape)\n",
    "    img = np.array(img)\n",
    "    img = img.astype('float32')\n",
    "    img /= 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "class CustomImageDataset:\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 3] # 3 is the column index of the label\n",
    "        #one hot encoding\n",
    "        label = np.eye(10)[label]\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     image = self.transform(image)\n",
    "        # if self.target_transform:\n",
    "        #     label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, batch_size=32, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.current_idx = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_idx >= len(self.dataset):\n",
    "            raise StopIteration\n",
    "        \n",
    "        # Get the next batch.\n",
    "        if self.current_idx + self.batch_size > len(self.dataset):\n",
    "            batch = [self.dataset[i] for i in range(self.current_idx, len(self.dataset))]\n",
    "            self.current_idx = len(self.dataset)\n",
    "        else:\n",
    "            batch = [self.dataset[i] for i in range(self.current_idx, self.current_idx + self.batch_size)]\n",
    "            self.current_idx += self.batch_size\n",
    "        \n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(batch)\n",
    "\n",
    "        images, labels = zip(*batch)\n",
    "        images = np.stack(images)\n",
    "        labels = np.stack(labels)\n",
    "\n",
    "        return images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomImageDataset(annotations_file= CSV_FILE, img_dir=IMAGE_DATASET_DIR)\n",
    "dataloader = CustomDataLoader(dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(MODEL_INIT_FILE)\n",
    "print(model)\n",
    "\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    # print(labels)\n",
    "    model.train(images, labels, learning_rate=0.0001, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_DIR = './TEST/'\n",
    "TEST_CSV_FILE = './TEST_csv.csv'\n",
    "\n",
    "test_dataset = CustomImageDataset(annotations_file= TEST_CSV_FILE, img_dir=TESTING_DIR)\n",
    "test_dataloader = CustomDataLoader(test_dataset, batch_size=48, shuffle=False)\n",
    "\n",
    "for images, labels in test_dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    print(model.predict(images))\n",
    "    print(model.evaluate(images, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfd499bf418f77ed98604f368b9dcc9d49d2a51ff3f93a138504985eb88a9fa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
