{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_INIT_FILE = 'model_desc.txt'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SOFTMAX LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_Layer:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'Softmax'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Layer\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        Z = np.exp(X)\n",
    "        return Z / np.einsum('ij->j', Z)\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        return np.copy(dZ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ReLU ACTIVATION </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU_Activation:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'ReLU'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Activation\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        Z = np.copy(X)\n",
    "        Z[Z < 0] = 0\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.copy(self.X)\n",
    "\n",
    "        dX[dX < 0] = 0\n",
    "        dX[dX > 0] = 1\n",
    "        return dX * dZ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FULLY CONNECTED LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fully_Connected_Layer:\n",
    "    def __init__(self, output_dim):\n",
    "        self.output_dim = output_dim\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Fully Connected Layer(output_dim={self.output_dim})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        if self.W is None:\n",
    "            self.W = np.random.randn(X.shape[1], self.output_dim) * math.sqrt(2 / X.shape[0])\n",
    "        \n",
    "        if self.b is None:\n",
    "            self.b = np.zeros((1, self.output_dim))\n",
    "\n",
    "        Z = np.einsum('ij,jk->ik', X, self.W) + self.b\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dW = np.einsum('ij,ik->jk', self.X, dZ) / self.X.shape[1] # check here\n",
    "        db = np.einsum('ij->j', dZ) / self.X.shape[0] # check here\n",
    "        dX = np.einsum('ij,jk->ik', dZ, self.W.T)\n",
    "\n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>FLATENNING LAYER</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatenning_Layer:\n",
    "    def __init__(self):\n",
    "        self.layer_type = 'Flatten'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} Layer\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.input_shape = X.shape\n",
    "        return X.reshape((X.shape[0], -1)) # check here\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.copy(dZ)\n",
    "        return dX.reshape(self.input_shape) # check here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MAX POOLING</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pooling:\n",
    "    def __init__(self, filter_dim, stride):\n",
    "        self.layer_type = 'Max Pooling'\n",
    "        self.filter_dim = filter_dim\n",
    "        self.stride = stride\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} (filter_dim={self.filter_dim}, stride={self.stride})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        self.output_dim = (X.shape[1] - self.filter_dim) // self.stride + 1\n",
    "        \n",
    "        Z = np.zeros((X.shape[0], self.output_dim, self.output_dim, X.shape[3]))\n",
    "\n",
    "        for i in range(self.output_dim):\n",
    "            for j in range(self.output_dim):\n",
    "                Z[:, i, j, :] = np.max(X[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :], axis=(1, 2))\n",
    "\n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dX = np.zeros(self.X.shape)\n",
    "\n",
    "        for i in range(self.output_dim):\n",
    "            for j in range(self.output_dim):\n",
    "                for k in range(dZ.shape[0]):\n",
    "                    max_index = np.argmax(self.X[k, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :])\n",
    "                    max_index = np.unravel_index(max_index, (self.filter_dim, self.filter_dim))\n",
    "                    dX[k, i*self.stride+max_index[0], j*self.stride+max_index[1], :] = dZ[k, i, j, :]\n",
    "        \n",
    "        return dX\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CONVOLUTION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, num_output_channels, filter_dim, stride=1, padding=0):\n",
    "        self.layer_type = 'Convolution'\n",
    "        self.num_output_channels = num_output_channels\n",
    "        self.filter_dim = filter_dim\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"{self.layer_type} (num_output_channels={self.num_output_channels}, filter_dim={self.filter_dim}, stride={self.stride}, padding={self.padding})\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "\n",
    "        self.output_dim = (X.shape[1] - self.filter_dim + 2 * self.padding) // self.stride + 1\n",
    "\n",
    "        Z = np.zeros((X.shape[0], self.output_dim, self.output_dim, self.num_output_channels))\n",
    "\n",
    "        for i in range(self.output_dim):\n",
    "            for j in range(self.output_dim):\n",
    "                Z[:, i, j, :] = np.einsum('ij,jkl->kl', X[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :], self.W) + self.b\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def backward(self, dZ, learning_rate=0.0001):\n",
    "        dW = np.zeros((self.filter_dim, self.filter_dim, self.X.shape[3], self.num_output_channels))\n",
    "        db = np.zeros((1, 1, 1, self.num_output_channels))\n",
    "        dX = np.zeros(self.X.shape)\n",
    "\n",
    "        for i in range(self.output_dim):\n",
    "            for j in range(self.output_dim):\n",
    "                dW = dW + np.einsum('ij,ikl->jkl', self.X[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :], dZ[:, i, j, :])\n",
    "                db = db + np.sum(dZ[:, i, j, :], axis=0)\n",
    "                dX[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :] = dX[:, i*self.stride:i*self.stride+self.filter_dim, j*self.stride:j*self.stride+self.filter_dim, :] + np.einsum('ij,jkl->ikl', dZ[:, i, j, :], self.W)\n",
    "        \n",
    "        self.W = self.W - learning_rate * dW\n",
    "        self.b = self.b - learning_rate * db\n",
    "\n",
    "        return dX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>MODEL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, filePath):\n",
    "        self.layers = []\n",
    "        self.filePath = filePath\n",
    "        self.build_model()\n",
    "\n",
    "    def __str__(self):\n",
    "        string = 'MODEL DETAILS:\\n\\n'\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            string += f\"Layer {i+1}: {layer}\\n\"\n",
    "        return string\n",
    "    \n",
    "    def build_model(self):\n",
    "        #check if file exists\n",
    "        if not os.path.exists(self.filePath):\n",
    "            print('File does not exist')\n",
    "            return\n",
    "        with open(self.filePath, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line == '':\n",
    "                    continue\n",
    "\n",
    "                line_split = line.split(' ')\n",
    "                layer_name = str(line_split[0]).upper()\n",
    "                \n",
    "                if layer_name == 'FC':\n",
    "                    output_dim = int(line_split[1])\n",
    "                    self.layers.append(Fully_Connected_Layer(output_dim))\n",
    "\n",
    "                elif layer_name == 'CONV':\n",
    "                    num_output_channels = int(line_split[1])\n",
    "                    filter_dim = int(line_split[2])\n",
    "                    stride = int(line_split[3])\n",
    "                    padding = int(line_split[4])\n",
    "                    self.layers.append(Convolution(num_output_channels, filter_dim, stride, padding))\n",
    "\n",
    "                elif layer_name == 'MAXPOOL':\n",
    "                    filter_dim = int(line_split[1])\n",
    "                    stride = int(line_split[2])\n",
    "                    self.layers.append(Max_Pooling(filter_dim, stride))\n",
    "\n",
    "                elif layer_name == 'FLATTEN':\n",
    "                    self.layers.append(Flatenning_Layer())\n",
    "\n",
    "                elif layer_name == 'RELU':\n",
    "                    self.layers.append(ReLU_Activation())\n",
    "\n",
    "                elif layer_name == 'SOFTMAX':\n",
    "                    self.layers.append(Softmax_Layer())\n",
    "                \n",
    "                else:\n",
    "                    print('Invalid layer name')\n",
    "                    return\n",
    "                \n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>BUILD MODEL FROM FILE</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL DETAILS:\n",
      "\n",
      "Layer 1: Convolution (num_output_channels=5, filter_dim=3, stride=1, padding=0)\n",
      "Layer 2: Max Pooling (filter_dim=2, stride=2)\n",
      "Layer 3: ReLU Activation\n",
      "Layer 4: Flatten Layer\n",
      "Layer 5: Fully Connected Layer(output_dim=10)\n",
      "Layer 6: Softmax Layer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model(MODEL_INIT_FILE)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
